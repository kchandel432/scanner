import hashlib
import pefile
import magic
import numpy as np
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List, Union

logger = logging.getLogger(__name__)

# Try to import YARA, make it optional
try:
    import yara
    YARA_AVAILABLE = True
except (ImportError, OSError) as e:
    logger.warning(f"YARA import failed: {e}. YARA-based scanning will be disabled.")
    YARA_AVAILABLE = False
    yara = None

import lief


class AdvancedMalwareScanner:
    def __init__(self):
        if YARA_AVAILABLE:
            self.rules = self._load_yara_rules()
        else:
            self.rules = None
            logger.warning("YARA library not found. YARA-based scanning will be disabled. "
                          "Run 'install_yara.bat' to install YARA for full functionality.")
        self.ai_model = self._load_ai_model()
        
    def _load_yara_rules(self) -> Optional[Any]:
        """Load YARA rules for pattern matching"""
        if not YARA_AVAILABLE:
            return None
        rules_path = Path("rules/malware_rules.yara")
        if rules_path.exists():
            try:
                return yara.compile(str(rules_path))
            except Exception as e:
                print(f"Warning: Failed to load YARA rules: {e}")
        return None
    
    def _load_ai_model(self):
        """Load pre-trained AI model"""
        from backend.utils.ai_engine import AIEngine
        engine = AIEngine.load_models()
        return engine
    
    def scan_file(self, file_path: Path) -> Dict[str, Any]:
        """Comprehensive file scanning"""
        results = {
            "file_info": {},
            "static_analysis": {},
            "dynamic_indicators": [],
            "ai_score": 0.0,
            "threat_level": "clean",
            "signatures": []
        }
        
        # Get file metadata
        file_info = self._analyze_file_metadata(file_path)
        results["file_info"] = file_info
        
        # Static analysis
        static_results = self._perform_static_analysis(file_path)
        results["static_analysis"] = static_results
        
        # YARA rule matching
        yara_matches = self._match_yara_rules(file_path)
        results["signatures"] = yara_matches
        
        # PE Analysis (if applicable)
        if file_info["file_type"] in ["exe", "dll", "sys"]:
            pe_results = self._analyze_pe_file(file_path)
            results["static_analysis"]["pe_analysis"] = pe_results
        
        # AI-based analysis
        ai_score = self._ai_analysis(file_path, static_results)
        results["ai_score"] = ai_score
        
        # Determine threat level
        threat_level = self._calculate_threat_level(
            yara_matches, ai_score, static_results
        )
        results["threat_level"] = threat_level
        
        return results
    
    def _analyze_file_metadata(self, file_path: Path) -> Dict[str, Any]:
        """Extract comprehensive file metadata"""
        stats = file_path.stat()
        
        return {
            "filename": file_path.name,
            "size": stats.st_size,
            "md5": self._calculate_hash(file_path, "md5"),
            "sha256": self._calculate_hash(file_path, "sha256"),
            "sha1": self._calculate_hash(file_path, "sha1"),
            "created": stats.st_ctime,
            "modified": stats.st_mtime,
            "file_type": magic.from_file(str(file_path), mime=True),
            "entropy": self._calculate_entropy(file_path)
        }
    
    def _calculate_hash(self, file_path: Path, algorithm: str) -> str:
        """Calculate file hash using specified algorithm"""
        hash_func = getattr(hashlib, algorithm)()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_func.update(chunk)
        return hash_func.hexdigest()
    
    def _calculate_entropy(self, file_path: Path) -> float:
        """Calculate Shannon entropy of file"""
        with open(file_path, "rb") as f:
            data = f.read()
        
        if not data:
            return 0.0
            
        entropy = 0
        for x in range(256):
            p_x = data.count(x) / len(data)
            if p_x > 0:
                entropy += -p_x * np.log2(p_x)
        
        return entropy
    
    def _perform_static_analysis(self, file_path: Path) -> Dict[str, Any]:
        """Perform static code/byte analysis"""
        analysis = {
            "suspicious_strings": [],
            "imports": [],
            "exports": [],
            "sections": [],
            "packer_detected": False,
            "obfuscation_score": 0
        }
        
        try:
            # Analyze binary with LIEF
            binary = lief.parse(str(file_path))
            if binary:
                # Extract imports
                analysis["imports"] = [
                    f"{imp.name} ({imp.library})"
                    for imp in binary.imports
                ]
                
                # Extract sections
                analysis["sections"] = [
                    {
                        "name": section.name,
                        "size": section.size,
                        "entropy": section.entropy,
                        "virtual_address": section.virtual_address
                    }
                    for section in binary.sections
                ]
                
                # Check for packers
                analysis["packer_detected"] = self._detect_packer(binary)
                
        except Exception as e:
            # If not a binary, analyze as text
            with open(file_path, "rb") as f:
                content = f.read()
                analysis["suspicious_strings"] = self._find_suspicious_strings(content)
        
        return analysis
    
    def _detect_packer(self, binary) -> bool:
        """Detect common packers and cryptors"""
        packer_signatures = [
            "UPX", "ASPack", "PECompact", "Themida", "VMProtect"
        ]
        
        for section in binary.sections:
            for packer in packer_signatures:
                if packer.lower() in section.name.lower():
                    return True
        
        # Check entropy for packed code
        high_entropy_sections = [
            s for s in binary.sections 
            if s.entropy > 7.0  # High entropy indicates possible packing
        ]
        
        return len(high_entropy_sections) > 0
    
    def _find_suspicious_strings(self, content: bytes) -> List[str]:
        """Find suspicious strings in file content"""
        suspicious_patterns = [
            b"CreateRemoteThread",
            b"VirtualAllocEx",
            b"WriteProcessMemory",
            b"ShellExecute",
            b"URLDownloadToFile",
            b"WinExec",
            b"system",
            b"eval(",
            b"exec(",
            b"base64_decode"
        ]
        
        found = []
        for pattern in suspicious_patterns:
            if pattern in content:
                try:
                    found.append(pattern.decode('utf-8', errors='ignore'))
                except:
                    found.append(str(pattern))
        
        return found
    
    def _match_yara_rules(self, file_path: Path) -> List[Dict[str, Any]]:
        """Match file against YARA rules"""
        matches = []
        if self.rules:
            try:
                yara_matches = self.rules.match(str(file_path))
                for match in yara_matches:
                    matches.append({
                        "rule": match.rule,
                        "tags": match.tags,
                        "meta": match.meta,
                        "strings": [str(s) for s in match.strings]
                    })
            except Exception as e:
                pass
        
        return matches
    
    def _analyze_pe_file(self, file_path: Path) -> Dict[str, Any]:
        """Detailed PE file analysis"""
        try:
            pe = pefile.PE(str(file_path))
            
            analysis = {
                "entry_point": pe.OPTIONAL_HEADER.AddressOfEntryPoint,
                "image_base": pe.OPTIONAL_HEADER.ImageBase,
                "sections": [],
                "imports": [],
                "exports": [],
                "has_tls": hasattr(pe, 'DIRECTORY_ENTRY_TLS'),
                "has_relocations": hasattr(pe, 'DIRECTORY_ENTRY_BASERELOC'),
                "suspicious_flags": []
            }
            
            # Analyze sections
            for section in pe.sections:
                section_info = {
                    "name": section.Name.decode().strip('\x00'),
                    "virtual_size": section.Misc_VirtualSize,
                    "virtual_address": section.VirtualAddress,
                    "raw_size": section.SizeOfRawData,
                    "characteristics": section.Characteristics,
                    "entropy": section.get_entropy()
                }
                analysis["sections"].append(section_info)
            
            # Check for suspicious characteristics
            suspicious_flags = []
            if pe.is_dll():
                suspicious_flags.append("DLL file")
            if pe.is_driver():
                suspicious_flags.append("Driver file")
            if pe.is_exe():
                # Check for packed executable
                if analysis["entry_point"] < 0x1000:
                    suspicious_flags.append("Possible packed executable")
            
            analysis["suspicious_flags"] = suspicious_flags
            
            return analysis
            
        except Exception as e:
            return {"error": str(e)}
    
    def _ai_analysis(self, file_path: Path, static_data: Dict) -> float:
        """AI-based threat analysis"""
        try:
            # Extract features for AI model
            features = self._extract_features(file_path, static_data)
            
            # Get prediction from AI model
            prediction = self.ai_model.predict([features])[0]
            confidence = self.ai_model.predict_proba([features])[0][1]
            
            return float(confidence)
        except Exception as e:
            # Fallback to heuristic analysis
            return self._heuristic_analysis(static_data)
    
    def _extract_features(self, file_path: Path, static_data: Dict) -> List[float]:
        """Extract features for AI model"""
        features = []
        
        # File size features
        file_size = static_data.get("file_info", {}).get("size", 0)
        features.append(np.log1p(file_size))
        
        # Entropy
        features.append(static_data.get("file_info", {}).get("entropy", 0))
        
        # Number of imports
        features.append(len(static_data.get("imports", [])))
        
        # Number of sections
        features.append(len(static_data.get("sections", [])))
        
        # Suspicious strings count
        features.append(len(static_data.get("suspicious_strings", [])))
        
        # Packer detection
        features.append(1.0 if static_data.get("packer_detected") else 0.0)
        
        return features
    
    def _heuristic_analysis(self, static_data: Dict) -> float:
        """Heuristic analysis when AI fails"""
        score = 0.0
        
        # Score based on suspicious strings
        suspicious_strings = static_data.get("suspicious_strings", [])
        score += min(len(suspicious_strings) * 0.1, 0.5)
        
        # Score for packer detection
        if static_data.get("packer_detected"):
            score += 0.3
        
        # Score for high entropy
        entropy = static_data.get("file_info", {}).get("entropy", 0)
        if entropy > 7.0:
            score += 0.2
        
        return min(score, 1.0)
    
    def _calculate_threat_level(self, yara_matches: List, ai_score: float, static_data: Dict) -> str:
        """Calculate final threat level"""
        # Start with AI score
        threat_score = ai_score
        
        # Add YARA matches weight
        threat_score += len(yara_matches) * 0.2
        
        # Add static analysis indicators
        if static_data.get("packer_detected"):
            threat_score += 0.3
        
        if len(static_data.get("suspicious_strings", [])) > 5:
            threat_score += 0.2
        
        # Determine threat level
        threat_score = min(threat_score, 1.0)
        
        if threat_score >= 0.8:
            return "critical"
        elif threat_score >= 0.6:
            return "high"
        elif threat_score >= 0.4:
            return "medium"
        elif threat_score >= 0.2:
            return "low"
        else:
            return "clean"
